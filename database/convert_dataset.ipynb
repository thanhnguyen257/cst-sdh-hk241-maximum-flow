{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMmYtiNxvuDz"
   },
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYHAhaJ96K-3"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy https://docs.google.com/spreadsheets/d/1f2zvYLYf033tYx3OLmdWaGXsRqk4apUZ/edit?usp=sharing&ouid=100299165652406824721&rtpof=true&sd=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vh8ZArYh6T4E"
   },
   "outputs": [],
   "source": [
    "!pip install -q openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jeXjeybsLBk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'maximum_flow_data.xlsx'\n",
    "\n",
    "try:\n",
    "  node = pd.read_excel(file_path, engine='openpyxl', sheet_name=\"Node\")\n",
    "  edge = pd.read_excel(file_path, engine='openpyxl', sheet_name=\"Edge\")\n",
    "  road = pd.read_excel(file_path, engine='openpyxl', sheet_name=\"Road\")\n",
    "except FileNotFoundError:\n",
    "  print(f\"Error: File '{file_path}' not found.\")\n",
    "except Exception as e:\n",
    "  print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVEiy5Wpvjz3"
   },
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7CMq01etklb"
   },
   "outputs": [],
   "source": [
    "df_node = node.dropna(subset=['Node','Location'])[['Node','Location']]\n",
    "df_node[['latitude', 'longitude']] = df_node['Location'].str.split(',', expand=True)\n",
    "df_node['latitude'] = df_node['latitude'].astype(float)\n",
    "df_node['longitude'] = df_node['longitude'].astype(float)\n",
    "df_node.rename(columns={'Node': 'name'}, inplace=True)\n",
    "df_node['name'] = df_node['name'].str.strip()\n",
    "df_node = df_node.drop(columns=['Location'])\n",
    "df_node = df_node.sort_values(by='name')\n",
    "df_node.reset_index(drop=True, inplace=True)\n",
    "df_node['id'] = range(0, len(df_node))\n",
    "df_node.to_csv('nodes.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe6abdEQvnc_"
   },
   "source": [
    "# Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUxPKJn_v0RM"
   },
   "outputs": [],
   "source": [
    "df_edge = edge.dropna()\n",
    "df_edge = df_edge.sort_values(by=['Path'])\n",
    "df_edge.rename(columns={'From': 'start', 'To': 'end', 'Capacity': 'capacity', 'Street name': 'name', 'Distance (Cost)': 'cost'}, inplace=True)\n",
    "df_edge['start'] = df_edge['start'].str.strip()\n",
    "df_edge['end'] = df_edge['end'].str.strip()\n",
    "df_edge['name'] = df_edge['name'].str.strip()\n",
    "df_edge['capacity'] = df_edge['capacity'].astype(int)\n",
    "df_edge['cost'] = df_edge['cost'].astype(int)\n",
    "\n",
    "node_id_map = dict(zip(df_node['name'], df_node['id']))\n",
    "node_coordinate_map = dict(zip(df_node['id'], zip( df_node['latitude'].astype(float) ,df_node['longitude'].astype(float))))\n",
    "\n",
    "df_edge['start_name'] = df_edge['start']\n",
    "df_edge['end_name'] = df_edge['end']\n",
    "df_edge['start'] = df_edge['start'].map(node_id_map)\n",
    "df_edge['end'] = df_edge['end'].map(node_id_map)\n",
    "df_edge['pair'] = list(zip(df_edge['start'].astype(int), df_edge['end'].astype(int)))\n",
    "\n",
    "df_edge['start_coordinate'] = df_edge['start'].map(node_coordinate_map)\n",
    "df_edge['end_coordinate'] = df_edge['end'].map(node_coordinate_map)\n",
    "\n",
    "df_edge['start_coordinate_str'] = df_edge['start_coordinate'].apply(lambda x: f\"{x[0]:.7f}, {x[1]:.7f}\".strip())\n",
    "df_edge['end_coordinate_str'] = df_edge['end_coordinate'].apply(lambda x: f\"{x[0]:.7f}, {x[1]:.7f}\".strip())\n",
    "df_edge['node_coordinate'] = df_edge.apply(lambda row: [(row['start_coordinate'][0], row['start_coordinate'][1]), (row['end_coordinate'][0], row['end_coordinate'][1])], axis=1)\n",
    "\n",
    "df_edge = df_edge.drop(columns=['Path','start_coordinate','end_coordinate'])\n",
    "df_edge.to_csv('edges.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4Jv0FPb2SkL"
   },
   "source": [
    "# Adjacent Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SANckD32ZKw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_nodes = len(df_node)\n",
    "capacity_adj_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "cost_adj_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "\n",
    "for _, row in df_edge.iterrows():\n",
    "    start_node = row['start']\n",
    "    end_node = row['end']\n",
    "    capacity = row['capacity']\n",
    "    capacity_adj_matrix[start_node, end_node] = capacity\n",
    "\n",
    "for _, row in df_edge.iterrows():\n",
    "    start_node = row['start']\n",
    "    end_node = row['end']\n",
    "    cost = row['cost']\n",
    "    cost_adj_matrix[start_node, end_node] = cost\n",
    "\n",
    "df_node_dict = df_node.set_index('id').to_dict('index')\n",
    "df_edge_dict = df_edge.set_index('pair').to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_Gc0WKq4u1R"
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQuqV1Kl6ovs"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy https://drive.google.com/file/d/1d3qRdIVbxKb_huF-M8rVmcPPZ0f_iDxq/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yQ6rXI_3E4Q"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_to_save = {\n",
    "    'df_node': df_node,\n",
    "    'df_edge': df_edge,\n",
    "    'capacity_adj_matrix': capacity_adj_matrix,\n",
    "    'cost_adj_matrix': cost_adj_matrix,\n",
    "    'df_node_dict': df_node_dict,\n",
    "    'df_edge_dict': df_edge_dict\n",
    "}\n",
    "\n",
    "with open('maximum_flow_data.pickle', 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)\n",
    "\n",
    "with open('maximum_flow_data.pickle', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "df_node = loaded_data['df_node']\n",
    "df_edge = loaded_data['df_edge']\n",
    "capacity_adj_matrix = loaded_data['capacity_adj_matrix']\n",
    "cost_adj_matrix = loaded_data['cost_adj_matrix']\n",
    "df_node_dict = loaded_data['df_node_dict']\n",
    "df_edge_dict = loaded_data['df_edge_dict']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
