{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_4Jv0FPb2SkL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load"
      ],
      "metadata": {
        "id": "dMmYtiNxvuDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://docs.google.com/spreadsheets/d/1Tl39_L8V8BwGLFkLTKmxJy2xMPTztAcP/edit?usp=sharing&ouid=100299165652406824721&rtpof=true&sd=true"
      ],
      "metadata": {
        "id": "XYHAhaJ96K-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openpyxl"
      ],
      "metadata": {
        "id": "Vh8ZArYh6T4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jeXjeybsLBk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/maximum_flow_data.xlsx'\n",
        "\n",
        "try:\n",
        "  node = pd.read_excel(file_path, engine='openpyxl', sheet_name=\"Node\")\n",
        "  edge = pd.read_excel(file_path, engine='openpyxl', sheet_name=\"Edge\")\n",
        "  matrix = pd.read_excel(file_path, engine='openpyxl', sheet_name=\"Matrix\")\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File '{file_path}' not found.\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nodes"
      ],
      "metadata": {
        "id": "DVEiy5Wpvjz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_node = node.dropna(subset=['Node','Location'])[['Node','Location']]\n",
        "df_node[['latitude', 'longitude']] = df_node['Location'].str.split(',', expand=True)\n",
        "df_node['latitude'] = df_node['latitude'].astype(float)\n",
        "df_node['longitude'] = df_node['longitude'].astype(float)\n",
        "df_node.rename(columns={'Node': 'name'}, inplace=True)\n",
        "df_node['name'] = df_node['name'].str.strip()\n",
        "df_node = df_node.drop(columns=['Location'])\n",
        "df_node = df_node.sort_values(by='name')\n",
        "df_node.reset_index(drop=True, inplace=True)\n",
        "df_node['id'] = range(0, len(df_node))\n",
        "df_node.to_csv('nodes.csv', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "j7CMq01etklb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edges"
      ],
      "metadata": {
        "id": "Pe6abdEQvnc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_edge = edge.dropna()\n",
        "df_edge = df_edge.sort_values(by=['Path'])\n",
        "df_edge = df_edge.drop(columns=['Path'])\n",
        "df_edge.rename(columns={'From': 'start', 'To': 'end', 'Weight': 'weight'}, inplace=True)\n",
        "df_edge['start'] = df_edge['start'].str.strip()\n",
        "df_edge['end'] = df_edge['end'].str.strip()\n",
        "df_edge['weight'] = df_edge['weight'].astype(int)\n",
        "\n",
        "node_id_map = dict(zip(df_node['name'], df_node['id']))\n",
        "\n",
        "df_edge['start'] = df_edge['start'].map(node_id_map)\n",
        "df_edge['end'] = df_edge['end'].map(node_id_map)\n",
        "\n",
        "df_edge.to_csv('edges.csv', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "hUxPKJn_v0RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjacent Matrix"
      ],
      "metadata": {
        "id": "_4Jv0FPb2SkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "num_nodes = len(df_node)\n",
        "adj_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
        "\n",
        "for _, row in df_edge.iterrows():\n",
        "    start_node = row['start']\n",
        "    end_node = row['end']\n",
        "    weight = row['weight']\n",
        "    adj_matrix[start_node, end_node] = weight\n",
        "\n",
        "df_node_dict = df_node.set_index('id').to_dict('index')"
      ],
      "metadata": {
        "id": "_SANckD32ZKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export"
      ],
      "metadata": {
        "id": "m_Gc0WKq4u1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/18u8HO4oBJB1Bv5YYMvQ9DUzHbodiPBW4/view?usp=sharing"
      ],
      "metadata": {
        "id": "zQuqV1Kl6ovs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# data_to_save = {\n",
        "#     'df_node': df_node,\n",
        "#     'df_edge': df_edge,\n",
        "#     'adj_matrix': adj_matrix,\n",
        "#     'df_node_dict': df_node_dict\n",
        "# }\n",
        "\n",
        "# with open('maximum_flow_data.pickle', 'wb') as f:\n",
        "#     pickle.dump(data_to_save, f)\n",
        "\n",
        "with open('maximum_flow_data.pickle', 'rb') as f:\n",
        "    loaded_data = pickle.load(f)\n",
        "\n",
        "df_node = loaded_data['df_node']\n",
        "df_edge = loaded_data['df_edge']\n",
        "adj_matrix = loaded_data['adj_matrix']\n",
        "df_node_dict = loaded_data['df_node_dict']"
      ],
      "metadata": {
        "id": "-yQ6rXI_3E4Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}